{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import uuid\n",
    "import cv2\n",
    "\n",
    "# necessary utilities\n",
    "mp_drawing = mp.solutions.drawing_utils # for the nodes on our hands\n",
    "mp_hands = mp.solutions.hands #for the hand model of mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_label(index, hand, results):\n",
    "    output = None\n",
    "    for idx ,c in enumerate(results.multi_handedness):\n",
    "        if(c.classification[0].index == index):\n",
    "            # here we extracted necessary information of the correct hand with the help of index\n",
    "            label  = c.classification[0].label\n",
    "            score = round(c.classification[0].score,2)\n",
    "            text = f\"{label} ({score})\"\n",
    "            \n",
    "            # using coordinates of the wrist\n",
    "            coor = [hand.landmark[mp_hands.HandLandmark.WRIST].x, hand.landmark[mp_hands.HandLandmark.WRIST].y]\n",
    "\n",
    "            # print(coor_to_print)\n",
    "            output = text, coor\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_joint_angle(image, results, joint_list):\n",
    "    \n",
    "    # Loop through hands\n",
    "    for hand in results.multi_hand_landmarks:\n",
    "        #Loop through joint sets \n",
    "        for joint in joint_list:\n",
    "            a = np.array([hand.landmark[joint[0]].x, hand.landmark[joint[0]].y]) # First coord\n",
    "            b = np.array([hand.landmark[joint[1]].x, hand.landmark[joint[1]].y]) # Second coord\n",
    "            c = np.array([hand.landmark[joint[2]].x, hand.landmark[joint[2]].y]) # Third coord\n",
    "            \n",
    "            radians = np.arctan2(c[1] - b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "            angle = np.abs(radians*180.0/np.pi)\n",
    "            \n",
    "            if angle > 180.0:\n",
    "                angle = 360-angle\n",
    "                \n",
    "            # window dimesions\n",
    "            dim = [image.shape[1],image.shape[0]]\n",
    "                \n",
    "            cv2.putText(image, str(round(angle, 2)), tuple(np.multiply(b, dim).astype(int)),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand detection\n",
    "def print_hand_labels(image, num, hand, results):\n",
    "    if(get_hand_label(num, hand, results)):\n",
    "        text , coordinates = get_hand_label(num, hand, results)\n",
    "        \n",
    "        # window dimesions\n",
    "        dim = [image.shape[1],image.shape[0]]\n",
    "        \n",
    "        # changing coordinates according to the window size\n",
    "        coor_to_print = tuple(np.multiply(np.array((hand.landmark[mp_hands.HandLandmark.WRIST].x, hand.landmark[mp_hands.HandLandmark.WRIST].y)),\n",
    "                    dim).astype(int))\n",
    "        \n",
    "        cv2.putText(image, text, coor_to_print, cv2.FONT_HERSHEY_SIMPLEX, 1, (1,0,0),2,cv2.LINE_AA)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1706426521.058223       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M1\n"
     ]
    }
   ],
   "source": [
    "#  Setting up the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# min_detection_condfidence for the accuracy on first time detection of our hand\n",
    "# min_tracking_confidence for the accuracy while hand tracking after detection\n",
    "with mp_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        # here frame is the image we get from our webcam\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # flip image on the horizontal\n",
    "        image = cv2.flip(frame,1)\n",
    "        \n",
    "        # cv2 captures image in BGR format which we want to convert into RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Set flag to prevent any changes in the image\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detection using the mediapipe model\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # Set flag to true to make changes in the image\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB TO BGR\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        # print(results)\n",
    "        \n",
    "        # rendering the results onto our image\n",
    "        if(results.multi_hand_landmarks):\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2))\n",
    "                \n",
    "                # for hand detection\n",
    "                print_hand_labels(image, num, hand, results)\n",
    "                    \n",
    "                # for angle prediction\n",
    "                joint_list=[[8,5,12]]\n",
    "                print_joint_angle(image, results, joint_list)\n",
    "\n",
    "        # output the feed of our webcam to our screen\n",
    "        cv2.imshow('Hand Tracking',image)\n",
    "        \n",
    "        # Save our image to a folder\n",
    "        cv2.imwrite(os.path.join('output images', '{}.jpg'.format(uuid.uuid1())), image)\n",
    "        \n",
    "        # Stop when we press 'q'\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_hand_landmarks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlandmark[mp_hands\u001b[38;5;241m.\u001b[39mHandLandmark\u001b[38;5;241m.\u001b[39mWRIST])\n\u001b[1;32m      2\u001b[0m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlandmark[mp_hands\u001b[38;5;241m.\u001b[39mHandLandmark\u001b[38;5;241m.\u001b[39mWRIST]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# results.multi_hand_landmarks\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(results.multi_hand_landmarks[0].landmark[mp_hands.HandLandmark.WRIST])\n",
    "results.multi_hand_landmarks[1].landmark[mp_hands.HandLandmark.WRIST]\n",
    "# results.multi_hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_handedness\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mclassification[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "results.multi_handedness[1].classification[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.10/site-packages (3.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Downloading PyAutoGUI-0.9.54.tar.gz (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m647.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyscreeze>=0.1.21\n",
      "  Downloading PyScreeze-0.1.30.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyobjc-framework-quartz\n",
      "  Downloading pyobjc_framework_Quartz-10.1-cp310-cp310-macosx_10_9_universal2.whl (230 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.0/231.0 kB\u001b[0m \u001b[31m812.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyobjc-core\n",
      "  Downloading pyobjc_core-10.1-cp310-cp310-macosx_10_9_universal2.whl (752 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m752.5/752.5 kB\u001b[0m \u001b[31m702.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting mouseinfo\n",
      "  Downloading MouseInfo-0.1.3.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytweening>=1.0.4\n",
      "  Downloading pytweening-1.0.7.tar.gz (168 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m805.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pygetwindow>=0.0.5\n",
      "  Downloading PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pymsgbox\n",
      "  Downloading PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyrect\n",
      "  Downloading PyRect-0.2.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=9.2.0 in ./venv/lib/python3.10/site-packages (from pyscreeze>=0.1.21->pyautogui) (10.2.0)\n",
      "Collecting pyperclip\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rubicon-objc\n",
      "  Downloading rubicon_objc-0.4.7-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m792.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyobjc-framework-Cocoa>=10.1\n",
      "  Downloading pyobjc_framework_Cocoa-10.1-cp310-cp310-macosx_10_9_universal2.whl (392 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m392.4/392.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing legacy 'setup.py install' for pygetwindow, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pytweening, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for mouseinfo, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pyperclip, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for pyrect, since package 'wheel' is not installed.\n",
      "Building wheels for collected packages: pyautogui, pyscreeze, pymsgbox\n",
      "  Building wheel for pyautogui (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyautogui: filename=PyAutoGUI-0.9.54-py3-none-any.whl size=37576 sha256=bc38f5f81d964489444fd12dfb4eb3ec361068babe96ce5fcadf4c7c501110cd\n",
      "  Stored in directory: /Users/omdeshmukh/Library/Caches/pip/wheels/23/a7/1c/5a51aaff3bbe110be4ddf766d429cc9d2fae7a72fc1b843e56\n",
      "  Building wheel for pyscreeze (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyscreeze: filename=PyScreeze-0.1.30-py3-none-any.whl size=14382 sha256=42f24a1b456b55e6bdf8cfca142bcf87ab9fc88e0fb4b4ce93a7597dfe024834\n",
      "  Stored in directory: /Users/omdeshmukh/Library/Caches/pip/wheels/c4/46/42/d3613adf9880c8b4a780c07a8cf85df12ca04a9a0ca77c6c02\n",
      "  Building wheel for pymsgbox (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7406 sha256=1a48dc268a880c38ae705eadf5f8885fb8d308607ef82954d2d7853554b2ee5b\n",
      "  Stored in directory: /Users/omdeshmukh/Library/Caches/pip/wheels/b9/6a/ba/be2d7d78166ec8018c21d07241dffa54446c09652a267759ae\n",
      "Successfully built pyautogui pyscreeze pymsgbox\n",
      "Installing collected packages: pytweening, pyrect, pyperclip, pymsgbox, rubicon-objc, pyscreeze, pyobjc-core, pygetwindow, pyobjc-framework-Cocoa, mouseinfo, pyobjc-framework-quartz, pyautogui\n",
      "  Running setup.py install for pytweening ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for pyrect ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for pyperclip ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for pygetwindow ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for mouseinfo ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed mouseinfo-0.1.3 pyautogui-0.9.54 pygetwindow-0.0.9 pymsgbox-1.0.9 pyobjc-core-10.1 pyobjc-framework-Cocoa-10.1 pyobjc-framework-quartz-10.1 pyperclip-1.8.2 pyrect-0.2.0 pyscreeze-0.1.30 pytweening-1.0.7 rubicon-objc-0.4.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# pyautogui.press('volumeup')\n",
    "!pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
